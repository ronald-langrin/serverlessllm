{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Serverless Llama3 deployment on GKE using VLLM and Keda Scaling Kubernetes to Zero (And Back) \n",
        "\n",
        "**(with OpenAI drop in replacement)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3de7470326a2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates deploying llama3 instruct using VLLM from a gcp bucket. In this notebook we will deploy and serve VLLM on GPUs. In this guide we specifically use L4 GPUs but this guide should also work for A100(40 GB), A100(80 GB), H100(80 GB) GPUs.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "Deploy and run inference for serving LLMS with VLLM on GPUs and scale to zero.\n",
        "\n",
        "### GPUs\n",
        "\n",
        "GPUs let you accelerate specific workloads running on your nodes such as machine learning and data processing. GKE provides a range of machine type options for node configuration, including machine types with NVIDIA H100, L4, and A100 GPUs.\n",
        "\n",
        "### VLLM\n",
        "\n",
        "VLLM is a highly optimized open-source LLM serving framework that can increase serving throughput on GPUs. VLLM includes features such as:\n",
        "\n",
        "Optimized transformer implementation with PagedAttention\n",
        "Continuous batching to improve the overall serving throughput\n",
        "Tensor parallelism and distributed serving on multiple GPUs\n",
        "\n",
        "### KEDA\n",
        "\n",
        "KEDA — the Kubernetes Event-Driven Autoscaler\n",
        "\n",
        "Kubernetes offers the Horizontal Pod Autoscaler (HPA) as a controller to increase and decrease replicas dynamically.\n",
        "\n",
        "\n",
        "Unfortunately, the HPA has a few drawbacks:\n",
        "\n",
        "1. It doesn’t work out of the box– you need to install a Metrics Server to aggregate and expose the metrics.\n",
        "\n",
        "2. It doesn’t scale to zero replicas.\n",
        "\n",
        "3. It scales replicas based on metrics, and doesn’t intercept HTTP traffic.\n",
        "\n",
        "4. Fortunately, you don’t have to use the official autoscaler, but you can use KEDA instead.\n",
        "\n",
        "\n",
        "KEDA is an autoscaler made of three components:\n",
        "\n",
        "1. A Scaler\n",
        "\n",
        "2. A Metrics Adapter\n",
        "\n",
        "3. A Controller\n",
        "\n",
        "### Prerequisites\n",
        "Install gcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264c07757582"
      },
      "source": [
        "## Run the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "855d6b96f291"
      },
      "outputs": [],
      "source": [
        "# Get the default cloud project id.\n",
        "PROJECT_ID = \"demo-project\"\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "REGION = \"demo-location\"\n",
        "\n",
        "NAMESPACE=\"vllm\"\n",
        "\n",
        "CLUSTER_NAME=f\"vllm-cluster-{PROJECT_ID}-3\"\n",
        "\n",
        "LLM_MODEL_ID=\"b0581263-c45a-4851-9e4b-b47e612a750e\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the neccesary libraties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /home/ronald/.local/lib/python3.9/site-packages (1.23.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/ronald/.local/lib/python3.9/site-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ronald/.local/lib/python3.9/site-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ronald/.local/lib/python3.9/site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/ronald/.local/lib/python3.9/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ronald/.local/lib/python3.9/site-packages (from openai) (0.23.3)\n",
            "Requirement already satisfied: sniffio in /home/ronald/.local/lib/python3.9/site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /home/ronald/.local/lib/python3.9/site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: exceptiongroup in /home/ronald/.local/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /home/ronald/.local/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
            "Requirement already satisfied: certifi in /home/ronald/.local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/ronald/.local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /home/ronald/.local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/ronald/.local/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /home/ronald/.local/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/ronald/.local/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Updated property [core/project].\n",
            "E: dpkg was interrupted, you must manually run 'sudo dpkg --configure -a' to correct the problem. \n",
            "E: dpkg was interrupted, you must manually run 'sudo dpkg --configure -a' to correct the problem. \n"
          ]
        }
      ],
      "source": [
        "# Install the openai client\n",
        "! pip install openai\n",
        "\n",
        "# Set up gcloud.\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "! gcloud services enable container.googleapis.com\n",
        "! sudo apt-get install kubectl\n",
        "! sudo apt-get install google-cloud-sdk-gke-gcloud-auth-plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an auto cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! gcloud container clusters create-auto {CLUSTER_NAME} \\\n",
        "    --project={PROJECT_ID} \\\n",
        "    --region={REGION} \\\n",
        "    --release-channel=rapid \\\n",
        "    --cluster-version=1.28 \\\n",
        "    --scopes=cloud-platform,storage-rw,cloud-source-repos \\\n",
        "    --create-subnetwork \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Login to cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! gcloud container clusters get-credentials {CLUSTER_NAME} --project {PROJECT_ID} --region {REGION}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the associated user and apply the neccesary service account and roles/permissions. Create a namespace and annotate the associated roles. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This line captures the output of the gcloud command into a list\n",
        "project_number = ! gcloud projects describe {PROJECT_ID} --format='value(projectNumber)'\n",
        "\n",
        "# Since the output is a list with the project number as its first element, access it with [0]\n",
        "gce_sa = f\"{project_number[0]}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "# List of roles you want to assign\n",
        "roles = [\"monitoring.metricWriter\", \"stackdriver.resourceMetadata.writer\"]\n",
        "\n",
        "# Loop over the roles and add IAM policy binding for each\n",
        "for role in roles:\n",
        "    !gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{gce_sa} --role=roles/{role}\n",
        "\n",
        "# Create a namespace in Kubernetes\n",
        "!kubectl create ns {NAMESPACE}\n",
        "\n",
        "# Create a service account in the newly created namespace\n",
        "!kubectl create serviceaccount {NAMESPACE} --namespace {NAMESPACE}\n",
        "\n",
        "# Add IAM policy binding to the GCE service account\n",
        "!gcloud iam service-accounts add-iam-policy-binding {gce_sa} \\\n",
        "    --role roles/iam.workloadIdentityUser \\\n",
        "    --member \"serviceAccount:{PROJECT_ID}.svc.id.goog[{NAMESPACE}/{NAMESPACE}]\"\n",
        "\n",
        "# Annotate the Kubernetes service account with the GCE service account\n",
        "!kubectl annotate serviceaccount {NAMESPACE} \\\n",
        "    --namespace {NAMESPACE} \\\n",
        "    iam.gke.io/gcp-service-account={gce_sa}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install Helm Binaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\n",
        "! chmod 700 get_helm.sh\n",
        "! ./get_helm.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install Keda Core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! helm repo add kedacore https://kedacore.github.io/charts\n",
        "! helm repo update\n",
        "! helm install keda kedacore/keda --namespace {NAMESPACE} --create-namespace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install Keda http addon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME: http-add-on\n",
            "LAST DEPLOYED: Sun May 12 17:01:00 2024\n",
            "NAMESPACE: vllm\n",
            "STATUS: deployed\n",
            "REVISION: 1\n",
            "TEST SUITE: None\n"
          ]
        }
      ],
      "source": [
        "! helm install http-add-on kedacore/keda-add-ons-http --namespace {NAMESPACE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install NGINX Ingress Controller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\n",
        "! helm repo update\n",
        "! helm install ingress-nginx ingress-nginx/ingress-nginx -n {NAMESPACE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set timeouts for scale up/down connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Release \"http-add-on\" has been upgraded. Happy Helming!\n",
            "NAME: http-add-on\n",
            "LAST DEPLOYED: Sun May 12 19:20:10 2024\n",
            "NAMESPACE: vllm\n",
            "STATUS: deployed\n",
            "REVISION: 3\n",
            "TEST SUITE: None\n"
          ]
        }
      ],
      "source": [
        "! helm upgrade http-add-on kedacore/keda-add-ons-http --namespace {NAMESPACE} \\\n",
        "  --set interceptor.replicas.waitTimeout=1000s \\\n",
        "  --set interceptor.responseHeaderTimeout=1000s \\\n",
        "  --set interceptor.expectContinueTimeout=1000s \\\n",
        "  --set interceptor.tcpConnectTimeout=1000s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modify KEDA_RESPONSE_HEADER_TIMEOUT which is the 6th environment variable listed. This should be set to your longest batched response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deployment.apps/keda-add-ons-http-interceptor patched\n"
          ]
        }
      ],
      "source": [
        "! kubectl patch deployment keda-add-ons-http-interceptor -n vllm --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/env/5/value\", \"value\":\"100s\"}]'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "6psJZY_zUDgj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deployment.apps \"vllm-deployment\" deleted\n",
            "deployment.apps/vllm-deployment created\n"
          ]
        }
      ],
      "source": [
        "# @title Deploy VLLM\n",
        "model_location = f\"/gcs-mount/models/{LLM_MODEL_ID}/model\"\n",
        "# @markdown This section deploys on VLLM.\n",
        "\n",
        "K8S_YAML = f\"\"\"\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: vllm-deployment\n",
        "spec:\n",
        "  replicas: 1\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: vllm-server\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: vllm-server\n",
        "        ai.gke.io/model: llm-7b\n",
        "        ai.gke.io/inference-server: vllm\n",
        "        examples.ai.gke.io/source: user-guide\n",
        "      annotations:\n",
        "        kubectl.kubernetes.io/default-container: vllm-server\n",
        "        gke-gcsfuse/volumes: \"true\"\n",
        "        gke-gcsfuse/cpu-limit: \"10\"\n",
        "        gke-gcsfuse/memory-limit: 10Gi\n",
        "        gke-gcsfuse/ephemeral-storage-limit: 1Ti\n",
        "        gke-gcsfuse/cpu-request: 500m\n",
        "        gke-gcsfuse/memory-request: 1Gi\n",
        "        gke-gcsfuse/ephemeral-storage-request: 50Gi\n",
        "    spec:\n",
        "      serviceAccountName: vllm\n",
        "      containers:\n",
        "      - name: vllm-server\n",
        "        #image: us-docker.pkg.dev/command-center-alpha/deployment/vllm:032\n",
        "        image: vllm/vllm-openai:latest\n",
        "        resources:\n",
        "          requests:\n",
        "            cpu: \"2\"\n",
        "            memory: \"25Gi\"\n",
        "            ephemeral-storage: \"25Gi\"\n",
        "            nvidia.com/gpu: 1\n",
        "          limits:\n",
        "            cpu: \"2\"\n",
        "            memory: \"25Gi\"\n",
        "            ephemeral-storage: \"25Gi\"\n",
        "            nvidia.com/gpu: 2\n",
        "        command: [\"python3\", \"-m\", \"vllm.entrypoints.openai.api_server\"]\n",
        "        args:\n",
        "        - --model={model_location}\n",
        "        - --gpu-memory-utilization=0.9\n",
        "        - --swap-space=0\n",
        "        - --dtype=half\n",
        "        - --quantization=gptq\n",
        "        - --tensor-parallel-size=1\n",
        "        - --port=8080\n",
        "        ports:\n",
        "        - containerPort: 8080\n",
        "        readinessProbe:\n",
        "          httpGet:\n",
        "            path: /health\n",
        "            port: 8080\n",
        "          initialDelaySeconds: 10\n",
        "          periodSeconds: 5\n",
        "          timeoutSeconds: 2\n",
        "          successThreshold: 1\n",
        "          failureThreshold: 3\n",
        "        volumeMounts:\n",
        "        - mountPath: /dev/shm\n",
        "          name: dshm\n",
        "        - mountPath: /gcs-mount\n",
        "          name: gcs-fuse-csi-ephemeral\n",
        "          readOnly: true\n",
        "      volumes:\n",
        "      - name: dshm\n",
        "        emptyDir:\n",
        "            medium: Memory\n",
        "      - name: gcs-fuse-csi-ephemeral\n",
        "        csi:\n",
        "          driver: gcsfuse.csi.storage.gke.io\n",
        "          volumeAttributes:\n",
        "            bucketName: {PROJECT_ID}\n",
        "            mountOptions: \"implicit-dirs\"\n",
        "            fileCacheCapacity: \"10Gi\"\n",
        "      nodeSelector:\n",
        "        cloud.google.com/gke-accelerator: nvidia-l4\n",
        "\"\"\"\n",
        "\n",
        "with open(\"vllm-deployment.yaml\", \"w\") as f:\n",
        "    f.write(K8S_YAML)\n",
        "\n",
        "! kubectl delete -f vllm-deployment.yaml -n {NAMESPACE}\n",
        "! kubectl apply -f vllm-deployment.yaml -n {NAMESPACE}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the service which references the \"vllm-server\" app, created in the previous deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "service \"vllm-server\" deleted\n",
            "service/vllm-server replaced\n"
          ]
        }
      ],
      "source": [
        "K8S_YAML = f\"\"\"\n",
        "apiVersion: v1\n",
        "kind: Service\n",
        "metadata:\n",
        " name: vllm-server\n",
        "spec:\n",
        " ports:\n",
        "   - port: 8080\n",
        "     targetPort: 8080\n",
        " selector:\n",
        "   app: vllm-server\n",
        "\"\"\"\n",
        "with open(\"vllm-service.yaml\", \"w\") as f:\n",
        "    f.write(K8S_YAML)\n",
        "\n",
        "!kubectl replace --force -f vllm-service.yaml -n {NAMESPACE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Scaled object which references the deployment and service previously created called \"vllm-server\" and \"vllm-deployment\" respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "httpscaledobject.http.keda.sh \"vllm-server\" deleted\n",
            "httpscaledobject.http.keda.sh/vllm-server replaced\n"
          ]
        }
      ],
      "source": [
        "K8S_YAML = f\"\"\"\n",
        "apiVersion: http.keda.sh/v1alpha1\n",
        "kind: HTTPScaledObject\n",
        "metadata:\n",
        "  name: vllm-server\n",
        "  namespace: vllm\n",
        "spec:\n",
        "  hosts: \n",
        "  - vllm.com\n",
        "  pathPrefixes:\n",
        "  - /v1\n",
        "  scaleTargetRef:\n",
        "    deployment: vllm-deployment\n",
        "    service: vllm-server\n",
        "    port: 8080\n",
        "  replicas:\n",
        "    min: 0\n",
        "    max: 3\n",
        "  scaledownPeriod: 300\n",
        "  scalingMetric: # requestRate and concurrency are mutually exclusive\n",
        "    concurrency:\n",
        "        targetValue: 100\n",
        "\"\"\"\n",
        "with open(\"vllm-keda.yaml\", \"w\") as f:\n",
        "    f.write(K8S_YAML)\n",
        "\n",
        "!kubectl replace --force -f vllm-keda.yaml -n {NAMESPACE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Ingress which references the \"scaled object\" via the host (vllm.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ingress.networking.k8s.io \"vllm-server\" deleted\n",
            "ingress.networking.k8s.io/vllm-server replaced\n"
          ]
        }
      ],
      "source": [
        "K8S_YAML = f\"\"\"\n",
        "apiVersion: networking.k8s.io/v1\n",
        "kind: Ingress\n",
        "metadata:\n",
        "  name: vllm-server\n",
        "  namespace: vllm\n",
        "  annotations:\n",
        "    nginx.ingress.kubernetes.io/upstream-vhost: vllm.com\n",
        "    nginx.ingress.kubernetes.io/proxy-read-timeout: \"1000\"\n",
        "    nginx.ingress.kubernetes.io/proxy-send-timeout: \"1000\"\n",
        "spec:\n",
        "  ingressClassName: nginx\n",
        "  rules:\n",
        "  - http:\n",
        "      paths:\n",
        "      - path: /\n",
        "        pathType: Prefix\n",
        "        backend:\n",
        "          service:\n",
        "            name: keda-add-ons-http-interceptor-proxy\n",
        "            port:\n",
        "              number: 8080\n",
        "\"\"\"\n",
        "with open(\"ingress-keda.yaml\", \"w\") as f:\n",
        "    f.write(K8S_YAML)\n",
        "\n",
        "!kubectl replace --force -f ingress-keda.yaml -n {NAMESPACE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run inference on the deployed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the openai client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "ip_address = !  kubectl get services -l \"app.kubernetes.io/component=controller\" -o jsonpath=\"{.items[0].status.loadBalancer.ingress[0].ip}\" -n vllm\n",
        "\n",
        "# @title Prediction\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "model_location = f\"/gcs-mount/models/{LLM_MODEL_ID}/model\"\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=f\"http://{ip_address[0]}/v1/\",\n",
        "    api_key=\"llama3\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batched response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content='Here is a 5-day workout routine that targets different muscle groups and includes a mix of cardio and strength training exercises:\\n\\n**Day 1: Chest and Triceps**\\n\\n1. Warm-up: 5-10 minutes of cardio (jogging, jumping jacks, etc.)\\n2. Barbell Bench Press: 3 sets of 8-12 reps\\n3. Incline Dumbbell Press: 3 sets of 10-15 reps\\n4. Tricep Pushdown: 3 sets of 12-15 reps\\n5. Tricep Dips: 3 sets of 12-15 reps\\n6. Cool-down: 5-10 minutes of stretching\\n\\n**Day 2: Back and Biceps**\\n\\n1. Warm-up: 5-10 minutes of cardio\\n2. Pull-ups: 3 sets of 8-12 reps (or Assisted Pull-ups if needed)\\n3. Barbell Rows: 3 sets of 8-12 reps\\n4. Dumbbell Bicep Curls: 3 sets of 10-15 reps\\n5. Hammer Curls: 3 sets of 10-15 reps\\n6. Cool-down: 5-10 minutes of stretching\\n\\n**Day 3: Legs**\\n\\n1. Warm-up: 5-10 minutes of cardio\\n2. Squats: 3 sets of 8-12 reps\\n3. Leg Press: 3 sets of 10-15 reps\\n4. Lunges: 3 sets of 10-15 reps (per leg)\\n5. Leg Extensions: 3 sets of 12-15 reps\\n6. Cool-down: 5-10 minutes of stretching\\n\\n**Day 4: Shoulders and Abs**\\n\\n1. Warm-up: 5-10 minutes of cardio\\n2. Seated Dumbbell Shoulder Press: 3 sets of 8-12 reps\\n3. Lateral Raises: 3 sets of 10-15 reps\\n4. Rear Delt Flys: 3 sets of 12-15 reps\\n5. Plank: 3 sets of 30-60 seconds\\n6. Cool-down: 5-10 minutes of stretching\\n\\n**Day 5: Cardio and Chest**\\n\\n1. Warm-up: 5-10 minutes of cardio\\n2. Treadmill or Stationary Bike: 20-30 minutes of steady-state cardio\\n3. Incline Bench Press: 3 sets of 8-12 reps\\n4. Cable Flys: 3 sets of 10-15 reps\\n5. Cool-down: 5-10 minutes of stretching\\n\\n**Additional Tips:**\\n\\n* Start with lighter weights and gradually increase the weight as you get stronger.\\n* Rest for 60-90 seconds between sets, and 120-180 seconds between exercises.\\n* Make sure to warm up properly before each workout, and cool down afterwards to prevent injury.\\n* Listen to your body and take rest days as needed.\\n* Adjust the routine as needed based on your fitness level and goals.\\n\\nRemember to consult with a doctor or a certified personal trainer before starting any new exercise program.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=f\"{model_location}\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Give me a 5 day workout routine\"},\n",
        "  ],\n",
        "  temperature=0,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Streaming response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is a 5-day workout routine that targets different muscle groups and includes a mix of cardio and strength training exercises:\n",
            "\n",
            "**Day 1: Chest and Triceps**\n",
            "\n",
            "1. Warm-up: 5-10 minutes of cardio (jogging, jumping jacks, etc.)\n",
            "2. Barbell Bench Press: 3 sets of 8-12 reps\n",
            "3. Incline Dumbbell Press: 3 sets of 10-15 reps\n",
            "4. Tricep Pushdown: 3 sets of 12-15 reps\n",
            "5. Tricep Dips: 3 sets of 12-15 reps\n",
            "6. Cool-down: 5-10 minutes of stretching\n",
            "\n",
            "**Day 2: Back and Biceps**\n",
            "\n",
            "1. Warm-up: 5-10 minutes of cardio\n",
            "2. Pull-ups: 3 sets of 8-12 reps (or Assisted Pull-ups if needed)\n",
            "3. Barbell Rows: 3 sets of 8-12 reps\n",
            "4. Dumbbell Bicep Curls: 3 sets of 10-15 reps\n",
            "5. Hammer Curls: 3 sets of 10-15 reps\n",
            "6. Cool-down: 5-10 minutes of stretching\n",
            "\n",
            "**Day 3: Legs**\n",
            "\n",
            "1. Warm-up: 5-10 minutes of cardio\n",
            "2. Squats: 3 sets of 8-12 reps\n",
            "3. Leg Press: 3 sets of 10-15 reps\n",
            "4. Lunges: 3 sets of 10-15 reps (per leg)\n",
            "5. Leg Extensions: 3 sets of 12-15 reps\n",
            "6. Cool-down: 5-10 minutes of stretching\n",
            "\n",
            "**Day 4: Shoulders and Abs**\n",
            "\n",
            "1. Warm-up: 5-10 minutes of cardio\n",
            "2. Seated Dumbbell Shoulder Press: 3 sets of 8-12 reps\n",
            "3. Lateral Raises: 3 sets of 10-15 reps\n",
            "4. Rear Delt Flys: 3 sets of 12-15 reps\n",
            "5. Plank: 3 sets of 30-60 seconds\n",
            "6. Cool-down: 5-10 minutes of stretching\n",
            "\n",
            "**Day 5: Cardio and Chest**\n",
            "\n",
            "1. Warm-up: 5-10 minutes of cardio\n",
            "2. Treadmill or Stationary Bike: 20-30 minutes of steady-state cardio\n",
            "3. Incline Bench Press: 3 sets of 8-12 reps\n",
            "4. Cable Flys: 3 sets of 10-15 reps\n",
            "5. Cool-down: 5-10 minutes of stretching\n",
            "\n",
            "**Additional Tips:**\n",
            "\n",
            "* Start with lighter weights and gradually increase the weight as you get stronger.\n",
            "* Rest for 60-90 seconds between sets, and 120-180 seconds between exercises.\n",
            "* Make sure to warm up properly before each workout, and cool down afterwards to prevent injury.\n",
            "* Listen to your body and take rest days as needed.\n",
            "* Adjust the routine as needed to fit your fitness level and goals.\n",
            "\n",
            "Remember to consult with a doctor or a certified personal trainer before starting any new exercise program."
          ]
        }
      ],
      "source": [
        "\n",
        "stream = client.chat.completions.create(\n",
        "  model=f\"{model_location}\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Give me a 5 day workout routine\"},\n",
        "  ],\n",
        "  temperature=0,\n",
        "  stream=True,\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content:\n",
        "        print(chunk.choices[0].delta.content, end='', flush=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uninstall and delete all helm charts \n",
        "! helm uninstall keda -n {NAMESPACE}\n",
        "! helm uninstall http-add-on -n {NAMESPACE}\n",
        "! helm uninstall ingress-nginx -n {NAMESPACE}\n",
        "! helm delete -n {NAMESPACE} http-add-on\n",
        "! helm delete -n {NAMESPACE} keda\n",
        "! helm delete -n {NAMESPACE} ingress-nginx\n",
        "\n",
        "# Delete all resources in the namespace \n",
        "! kubectl delete all --all -n {NAMESPACE}\n",
        "\n",
        "# Delete the cluster\n",
        "! gcloud container clusters delete {CLUSTER_NAME} --region={REGION} --quiet "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_gemma_deployment_on_gke.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
